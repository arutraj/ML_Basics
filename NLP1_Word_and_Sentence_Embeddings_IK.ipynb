{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arutraj/ML_Basics/blob/main/NLP1_Word_and_Sentence_Embeddings_IK.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ki6jcwCjGwk1"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eo4S8f58Gwk9"
      },
      "source": [
        "# Word Embeddings\n",
        "## Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "yYyDkHMSGwk_"
      },
      "outputs": [],
      "source": [
        "# First, you'll need to install gensim\n",
        "# !pip install gensim\n",
        "\n",
        "# Import the necessary modules\n",
        "\n",
        "from gensim.test.utils import common_texts\n",
        "\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0FCHyZ0GwlB",
        "outputId": "eef5a449-fd79-43c3-d358-751fc96252e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['human', 'interface', 'computer'], ['survey', 'user', 'computer', 'system', 'response', 'time'], ['eps', 'user', 'interface', 'system'], ['system', 'human', 'system', 'eps'], ['user', 'response', 'time'], ['trees'], ['graph', 'trees'], ['graph', 'minors', 'trees'], ['graph', 'minors', 'survey']]\n"
          ]
        }
      ],
      "source": [
        "print(common_texts) #Sample Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "obAnQvieGwlE"
      },
      "source": [
        " Word2vec accepts several parameters that affect both training speed and quality.\n",
        "\n",
        "One of them is for pruning the internal dictionary. Words that appear only once or twice in a billion-word corpus are probably uninteresting typos and garbage. In addition, there’s not enough data to make any meaningful training on those words, so it’s best to ignore them:\n",
        "\n",
        "`model = Word2Vec(sentences, min_count=10)  # default value is 5`\n",
        "\n",
        "A reasonable value for min_count is between 0-100, depending on the size of your dataset.\n",
        "\n",
        "Another parameter is the size of the NN layers, which correspond to the “degrees” of freedom the training algorithm has:\n",
        "\n",
        "`model = Word2Vec(sentences, vector_size=200)  # default value is 100`\n",
        "\n",
        "Bigger size values require more training data, but can lead to better (more accurate) models. Reasonable values are in the tens to hundreds."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other hyper-parameters:\n",
        "\n",
        "*   size: window=window_size for capturing context for target word\n",
        "\n",
        "*   sample: The threshold for configuring which higher-frequency words are randomly down sampled, useful range is (0, 1e-5)\n",
        "\n",
        "*   workers: Use these many worker threads to train the model (faster training with multicore machines)\n",
        "\n",
        "*   sg: Training algorithm: skip-gram if sg=1, otherwise CBOW.\n",
        "\n",
        "*   iter: Number of iterations (epochs) over the corpus.\n"
      ],
      "metadata": {
        "id": "eHJa7t_dVlNi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "enTdB5hPGwlH"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(sentences=common_texts, vector_size=10, window=5, min_count=1, workers=4)\n",
        "#Here, vector_size = 10 denotes the length of embedding\n",
        "model.save(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yiL5GEqaGwlJ"
      },
      "source": [
        "If you save the model you can continue training it later:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EVn5-eMTGwlK"
      },
      "outputs": [],
      "source": [
        "# load the saved model\n",
        "model = Word2Vec.load(\"word2vec.model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcwKsP0OGwlM"
      },
      "source": [
        "The trained word vectors are stored in a KeyedVectors instance, as model.wv:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "LQ-S-El4GwlO",
        "outputId": "ca7913eb-3873-476d-a46a-fa243d89abc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00410223 -0.08368949 -0.05600012  0.07104538  0.0335254   0.0722567\n",
            "  0.06800248  0.07530741 -0.03789154 -0.00561806]\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "# Get the embeddings for the word 'human'\n",
        "embedding = model.wv['human']\n",
        "\n",
        "print(embedding)\n",
        "print(len(embedding))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "2zWtQqtrGwlP",
        "outputId": "422fa766-b7a1-41b0-8606-3e471bcb2549",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('graph', 0.3586882948875427), ('system', 0.22743132710456848), ('response', 0.11532396823167801)]\n"
          ]
        }
      ],
      "source": [
        "# Get the most similar words (having the most similar embeddings)\n",
        "similar_words = model.wv.most_similar('human',topn = 3) #topn denotes the top 3 similar words\n",
        "print(similar_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NrllmXJqGwlR"
      },
      "outputs": [],
      "source": [
        "# Store just the words + their trained embeddings.\n",
        "word_vectors = model.wv\n",
        "word_vectors.save(\"word2vec.wordvectors\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "PFj9xhGgGwlS",
        "outputId": "02355f50-f2f2-42a6-b6a0-7640314b808f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.01632109,  0.00189991,  0.03474986,  0.00217862,  0.09622561,\n",
              "        0.05062568, -0.08920852, -0.07044294,  0.00901806,  0.06395016],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Load back with memory-mapping = read-only, shared across processes.\n",
        "from gensim.models import KeyedVectors\n",
        "wv = KeyedVectors.load(\"word2vec.wordvectors\", mmap='r')\n",
        "wv['computer']  # Get numpy vector embedding for 'computer'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Hme83l4GwlT"
      },
      "source": [
        "### Refer to the link below for more details:\n",
        "https://radimrehurek.com/gensim/models/word2vec.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kM6M_oYAGwlU"
      },
      "source": [
        "# Gensim comes with several already pre-trained models, in the Gensim-data repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WEvTubVQGwlV",
        "outputId": "3553761e-2834-4ad1-d2f7-5ffa9c74ee8c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader\n",
        "# Show all available models in gensim-data\n",
        "print(list(gensim.downloader.info()['models'].keys()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0gl5eMeCGwlV",
        "outputId": "fd4cafbc-bb65-433c-d986-7e872461303a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.KeyedVectors at 0x7ee5798188b0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Download the \"glove-twitter-25\" embeddings\n",
        "# Pre-trained glove vectors based on 2B tweets, 27B tokens, 1.2M vocab, uncased.\n",
        "glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
        "glove_vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CcG_GXoUGwlX",
        "outputId": "5c223915-30f5-4070-985b-331180083b36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('facebook', 0.948005199432373),\n",
              " ('tweet', 0.9403423070907593),\n",
              " ('fb', 0.9342358708381653),\n",
              " ('instagram', 0.9104824066162109),\n",
              " ('chat', 0.8964964747428894),\n",
              " ('hashtag', 0.8885937333106995),\n",
              " ('tweets', 0.8878158330917358),\n",
              " ('tl', 0.8778461217880249),\n",
              " ('link', 0.8778210878372192),\n",
              " ('internet', 0.8753897547721863)]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Use the downloaded vectors as usual:\n",
        "glove_vectors.most_similar('twitter')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvnW9NgBGwla"
      },
      "source": [
        "# Document/Sentence Embeddings\n",
        "Paragraph, Sentence, and Document embeddings\n",
        "\n",
        "## Doc2vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "If7cxdRzGwlj",
        "outputId": "039709f6-aae2-437a-e276-2a03d7af4ebe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence Embeddings:\n",
            "[array([-0.02651018,  0.00345225,  0.02950032, -0.00521099,  0.02622059,\n",
            "       -0.04415315,  0.03949709,  0.0347003 , -0.0355242 ,  0.0355443 ],\n",
            "      dtype=float32), array([-0.00355846, -0.01089069,  0.01064902, -0.03510013,  0.0489391 ,\n",
            "        0.00149197, -0.00687361,  0.02762178,  0.02065086, -0.01745699],\n",
            "      dtype=float32), array([-0.03286843,  0.02593765,  0.01603379, -0.04145756, -0.03280213,\n",
            "        0.01090155,  0.03253587, -0.03788246,  0.02422524,  0.03906832],\n",
            "      dtype=float32), array([-0.00464409, -0.00556819,  0.02142883, -0.00206426, -0.02979414,\n",
            "        0.03101977,  0.04085322, -0.01811217,  0.04930789, -0.01411656],\n",
            "      dtype=float32), array([-0.03791236, -0.02003873, -0.01327085,  0.00074965, -0.04746118,\n",
            "       -0.04426737, -0.01107387,  0.00713651, -0.0143    , -0.0122711 ],\n",
            "      dtype=float32)]\n",
            "\n",
            "Shape:\n",
            "(5, 10)\n"
          ]
        }
      ],
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "# Define your sentences (example)\n",
        "sentences = [\"this is the first sentence\", \"this is the second sentence\", \"yet another sentence\", \"one more sentence\", \"and the final sentence\"]\n",
        "\n",
        "# Tag the sentences for training\n",
        "tagged_data = [TaggedDocument(words=sentence.split(), tags=[str(i)]) for i, sentence in enumerate(sentences)]\n",
        "\n",
        "# Train the model\n",
        "model = Doc2Vec(tagged_data, vector_size=10, window=2, min_count=1, workers=4)\n",
        "\n",
        "# Get the embeddings for the sentences\n",
        "sentence_vectors = [model.infer_vector(sentence.split()) for sentence in sentences]\n",
        "# The infer_vectors expects the input as a list of words (nltk.word_tokenize())\n",
        "\n",
        "print(\"Sentence Embeddings:\")\n",
        "print(sentence_vectors) #Embeddings of the sentences\n",
        "\n",
        "import numpy as np\n",
        "print(\"\\nShape:\")\n",
        "print(np.array(sentence_vectors).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "bF1RI8k8Gwlk",
        "outputId": "562519cf-68b8-4770-bc10-5df52b6471fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.02651018  0.00345225  0.02950032 -0.00521099  0.02622059 -0.04415315\n",
            "  0.03949709  0.0347003  -0.0355242   0.0355443 ]\n"
          ]
        }
      ],
      "source": [
        "print(sentence_vectors[0]) #the first embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-XesFtYhGwll",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c49db47-c3b4-4dd0-871e-ca7fa96fab26"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.2199869"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "cosine_similarity(sentence_vectors[1].reshape(1,-1),sentence_vectors[2].reshape(1,-1))[0][0]\n",
        "#Cosine similarity between embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0DKoWDb-Gwln",
        "outputId": "e9bbf4e7-de69-42f0-ba3f-469a4b8c4567",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  0.15361078,  0.08465073, -0.32718945,  0.14108971],\n",
              "       [ 0.15361078,  0.99999994, -0.2199869 , -0.0894393 , -0.33247685],\n",
              "       [ 0.08465073, -0.2199869 ,  0.99999994,  0.54031366,  0.01249529],\n",
              "       [-0.32718945, -0.0894393 ,  0.54031366,  1.        , -0.15579385],\n",
              "       [ 0.14108971, -0.33247685,  0.01249529, -0.15579385,  0.99999994]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Find the similarity between all the sentences\n",
        "similarity = cosine_similarity(sentence_vectors)\n",
        "similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "H_8s2ff2Gwlo",
        "outputId": "5ebdfb7a-14ab-4e6d-e92c-77fe569298c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input Sentence --> this is the first sentence\n",
            "Most Similar Sentence --> this is the second sentence\n",
            "Cosine Simialrity: 0.1536108\n"
          ]
        }
      ],
      "source": [
        "#Find the most similar sentence to the first sentence (at index = 0)\n",
        "idx = 0  # The index of the sentence for which you want to find the most similar sentence\n",
        "max = -1 # This will store the cosine_similarity of the most similar document\n",
        "max_idx = -1\n",
        "print(\"Input Sentence -->\", sentences[idx])\n",
        "for i in range(np.array(sentence_vectors).shape[0]):\n",
        "    if i == idx:\n",
        "      continue\n",
        "    sim = cosine_similarity(sentence_vectors[i].reshape(1,-1),\n",
        "                            sentence_vectors[idx].reshape(1,-1))[0][0]\n",
        "    if max < sim:\n",
        "        max = sim\n",
        "        max_idx = i\n",
        "\n",
        "print(\"Most Similar Sentence -->\", sentences[max_idx])\n",
        "print(\"Cosine Simialrity:\", max)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZynnc0BGwlp"
      },
      "source": [
        "#### More about Doc2vec here:\n",
        "https://radimrehurek.com/gensim/models/doc2vec.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S58AcfXwj0Wo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}